{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f5da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision.models as models\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## Pytorch & Torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "## Custom dataset\n",
    "from CustomData import NFDataset\n",
    "CSV_path =  \".\\\\Noise&Face_CSV\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d925b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for setting the seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "#Set seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e9b97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? True\n",
      "Device: cuda\n",
      "Device name: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "#GPU check and setup\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.determinstic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "#Check for cuda GPU to run on:\n",
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if gpu_avail:\n",
    "    print(\"Device name: \" + torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe00d54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f836606df24c108c136e55ac60a4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: tensor([0.3137])\n",
      "STD: tensor([0.2816])\n"
     ]
    }
   ],
   "source": [
    "# Calc mean and std\n",
    "\n",
    "test_transform =  transforms.Compose([transforms.ToPILImage(),\n",
    "                                      transforms.Resize((32,32)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])\n",
    "\n",
    "dataset = NFDataset(csv_file = CSV_path+\"NF_train.csv\", root_dir = '.\\\\', transform = test_transform)\n",
    "loader = DataLoader(dataset=dataset, batch_size=128, shuffle=True, drop_last=False, num_workers=4)\n",
    "\n",
    "def batch_mean_and_sd(loader):\n",
    "    \n",
    "    cnt = 0\n",
    "    fst_moment = torch.empty(1)\n",
    "    snd_moment = torch.empty(1)\n",
    "\n",
    "    for images, _ in tqdm(loader):\n",
    "        b, c, h, w = images.shape\n",
    "        nb_pixels = b * h * w\n",
    "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
    "        sum_of_square = torch.sum(images ** 2,\n",
    "                                  dim=[0, 2, 3])\n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
    "        cnt += nb_pixels\n",
    "\n",
    "    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)        \n",
    "    return mean,std\n",
    "  \n",
    "mean, std = batch_mean_and_sd(loader)\n",
    "print (\"MEAN:\", mean)\n",
    "print (\"STD:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f323d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean, std)\n",
    "                                     ])\n",
    "test_transform =  transforms.Compose([transforms.ToPILImage(),\n",
    "                                      transforms.Resize((32,32)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean, std)\n",
    "                                     ])\n",
    "\n",
    "# Split the sets\n",
    "train_dataset = NFDataset(csv_file = CSV_path+\"NF_train.csv\", root_dir = '.\\\\', transform = train_transform)\n",
    "val_dataset = NFDataset(csv_file = CSV_path+\"NF_train.csv\", root_dir = '.\\\\', transform = test_transform)\n",
    "set_seed(42)\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [14936,3734])\n",
    "set_seed(42)\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [14936,3734])\n",
    "test_set = NFDataset(csv_file = CSV_path+\"NF_test.csv\", root_dir = '.\\\\', transform = test_transform)\n",
    "\n",
    "# Define a set of data loaders\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=128, shuffle=True, drop_last=False, num_workers=4)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=128,shuffle=True, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4549574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([128, 1, 32, 32])\n",
      "Labels batch shape: torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Print a sample of the training data\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e86168ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch mean tensor([0.0994])\n",
      "Batch std tensor([0.9860])\n"
     ]
    }
   ],
   "source": [
    "# To verify that our normalization works, we can print out the mean and standard deviation of the single batch.\n",
    "# The mean should be close to 0 and the standard deviation close to 1 for each channel:\n",
    "imgs, _ = next(iter(train_loader))\n",
    "print(\"Batch mean\", imgs.mean(dim=[0,2,3]))\n",
    "print(\"Batch std\", imgs.std(dim=[0,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca1055cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "  def __init__(self, n_chans):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias=False)\n",
    "    self.dropout = nn.Dropout2d(p = 0.3)\n",
    "  def forward(self, x):\n",
    "    out = self.conv(x)\n",
    "    out = self.dropout(out)\n",
    "    out = torch.relu(out)\n",
    "    return out + x\n",
    "class ResNet10D(nn.Module):\n",
    "    def __init__(self, n_chans1=128, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(1, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef3dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet10D(\n",
      "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (resblocks): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "    (9): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=8192, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = ResNet10D().to(device=device)\n",
    "\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "357f39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and validation functions for first model:\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            \n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "            \n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5062f039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179ee590c7894115a2c7fd95b25a7ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-07 13:43:18.059243 Epoch 1, Training loss 1.519956545583133\n",
      "2022-05-07 13:45:08.470043 Epoch 10, Training loss 0.0068900594141551065\n",
      "2022-05-07 13:47:11.902695 Epoch 20, Training loss 0.0030748122433202486\n",
      "2022-05-07 13:49:14.764567 Epoch 30, Training loss 0.0010563774641045242\n",
      "2022-05-07 13:51:18.631877 Epoch 40, Training loss 0.0008438453624907636\n",
      "2022-05-07 13:53:20.770347 Epoch 50, Training loss 0.0006360444308307737\n",
      "Accuracy train: 1.00\n",
      "Accuracy val: 1.00\n"
     ]
    }
   ],
   "source": [
    "# defining the optimizer\n",
    "#optimizer = Adam(model.parameters(), lr=0.07)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device=device)\n",
    "    \n",
    "training_loop(\n",
    "    n_epochs = 50,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03af220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a80f1a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is true [0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0\n",
      " 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1\n",
      " 1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1 1]\n",
      "Predictions [0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0\n",
      " 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1\n",
      " 1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = next(iter(test_loader))\n",
    "model_out = model(test_features.to(device=device))\n",
    "ytrue = test_labels\n",
    "ypred = torch.argmax(model_out, axis =1)\n",
    "ytrue = ytrue.to('cpu').detach().numpy()\n",
    "ypred = ypred.to('cpu').detach().numpy()\n",
    "print(\"This is true\", ytrue)\n",
    "print(\"Predictions\",ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1e37ff2-82bb-4fc4-a0b2-c6e35e7461f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "import seaborn as sns \n",
    "mat = confusion_matrix(ytrue, ypred) \n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, \n",
    "            xticklabels=['No Face','Face'], \n",
    "            yticklabels=['No Face','Face',]) \n",
    "plt.xlabel('true label') \n",
    "plt.ylabel('predicted label'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a64ba0-3459-4f40-9e58-0451cd636095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
